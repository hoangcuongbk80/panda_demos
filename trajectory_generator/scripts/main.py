#!/usr/bin/env python
import os
from os import listdir
from os.path import isfile, join
import sys
import math
import json
import torch
import random
import argparse
import importlib
import rospy
# rospy.init_node('main_learning_loop', anonymous=True)

import plotter_from_generated as plotter_module
from torch.distributions.multivariate_normal import MultivariateNormal

from datetime import datetime
import ast

import rospkg
rospack = rospkg.RosPack()
package_path = rospack.get_path("trajectory_generator")

parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')
parser.add_argument('--gamma', type=float, default=0.99, metavar='G', help='discount factor (default: 0.99)')
parser.add_argument('--seed', type=int, default=543, metavar='N', help='random seed (default: 543)')
parser.add_argument('--no-cuda', action='store_true', default=False, help='enables CUDA training')

parser.add_argument('--pre-train-log-interval', type=int, default=10, metavar='N', help='interval between training status logs (default: 100)')
parser.add_argument('--pre-train-epochs', type=int, default=100, help='number of epochs for training (default: 1000)')
parser.add_argument('--pre-train-batch-size', type=int, default=100, metavar='N', help='input batch size for training (default: 1000)')
parser.add_argument('--log-interval', type=int, default=1, metavar='N', help='interval between training status logs (default: 1)')
parser.add_argument('--epochs', type=int, default=12, help='number of epochs for training (default: 10)')
parser.add_argument('--batch-size', type=int, default=5, metavar='N', help='input batch size for training (default: 12)')
parser.add_argument('--action-repetition', type=int, default=3 , help='number of times to  repeat the same action')
parser.add_argument('--test-repetition', type=int, default=5 , help='number of times to  repeat the same action while testing the deterministic policy')
parser.add_argument('--performance-repetition', type=int, default=5 , help='number of times to  repeat the same action while testing the performance metric of the deterministic policy')
parser.add_argument('--safe-throws', type=int, default=180 , help='number of safe throws to execute before stopping the learning loop')
parser.add_argument('--reward-type', default="discrete" , help='type of reward function to use during learning')

parser.add_argument('--state-dim', type=int, default=4, help='policy input dimension (default: 4)')
parser.add_argument('--action-dim', type=int, default=5, help='policy output dimension (default: 5)')
parser.add_argument('--learning-rate', type=float, default=0.1, help='learning rate of the optimizer')

parser.add_argument('--models-dir', default="nn_models", help='directory from where to load the network shape of the action decoder')
parser.add_argument('--decoder-model-file', default="model_trajectory_vae", help='file from where to load the network shape of the action decoder')
parser.add_argument('--decoder-dir', default=package_path + "/saved_models/trajectory_vae/", help='directory from where to load the trained model of the action decoder')
parser.add_argument('--decoder-sd', default=False, help='file from where to load the trained model of the action decoder')
parser.add_argument('--encoder-model-file', default="model_state_vae", help='file from where to load the network shape of the state encoder')
parser.add_argument('--encoder-dir', default=package_path + "/saved_models/state_vae/", help='directory from where to load the trained model of the state encoder')
parser.add_argument('--encoder-sd', default=False, help='file from where to load the trained model of the state encoder')
parser.add_argument('--latent-space-data', nargs='?', const=True, default=False, help='file from where to load the data of the latent space')
parser.add_argument('--algorithm-dir', default="learning_algorithms", help='directory from where to load the learning algorithm')
parser.add_argument('--algorithm', default="pytorch_reinforce", help='file from where to load the learning algorithm')
parser.add_argument('--scripts-dir', default=package_path + "/scripts/", help='directory from where to load the scripts')
parser.add_argument('--image-reader', default="imager", help='file from where to load the learning algorithm')
parser.add_argument('--sensing-script', default="stone_sensing", help='file from where to load the sensing script')
parser.add_argument('--action-script', default="writer_from_generated", help='file from where to load the action script')
parser.add_argument('--safety-check-script', default="safety_check_client", help='script for the trajectory safety check')
parser.add_argument('--trajectory-writer-script', default="writer_from_generated", help='script publishing the trajectory')

parser.add_argument('--no-plot', nargs='?', const=True, default=False, help='whether to plot data or not')
parser.add_argument('--safe-execution-time', type=int, default=9000000000, help='safe execution time in nanoseconds')
parser.add_argument('--execution-time', type=int, default=1700000000, help='execution time in nanoseconds')
parser.add_argument('--release-frame', type=int, default=95, help='release frame')

parser.add_argument('--save-dir', default=package_path + "/saved_models/policy_network/", help='directory where to save the policy model once trained')
parser.add_argument('--save-checkpoint', default=package_path + "/saved_models/policy_network/checkpoint/", help='directory where to save the policy model once trained')
parser.add_argument('--save-file', default=False, help='name of the file to save the policy model once trained')
parser.add_argument('--load-dir', default=package_path + "/saved_models/policy_network/", help='directory from where to load the trained policy model')
parser.add_argument('--load-checkpoint', default=False, help='name of the file containing the checkpoint of the trained policy model')
parser.add_argument('--load-file', default=False, help='name of the file containing the state dictionary of the trained policy model')
parser.add_argument('--measure-performance', nargs='?', const=True, default=False, help='whether or not to test the performance of the policy')
parser.add_argument('--collect-state-data', nargs='+', default=False, help='list of the labels of the stones')
# parser.add_argument('--stones-labels', nargs='+', default=None, type=str, help='list of the labels of the stones')

parser.add_argument('--trajectory-folder', default="latest", help='folder where to look for the trajectory to execute')
parser.add_argument('--trajectory-file', default="trajectories.txt", help='file describing the trajectory to follow')
parser.add_argument('--state-folder', default="latest", help='folder where to save the state data')
parser.add_argument('--state-repetitions', default=50, type=int, help='number of repetitions for each label')

args, unknown = parser.parse_known_args()
# args = parser.parse_args()

args.trajectory_folder = package_path + "/generated_trajectories/cpp/" + args.trajectory_folder + "/"
args.cuda = not args.no_cuda and torch.cuda.is_available()
# device = torch.device("cuda" if args.cuda else "cpu")
device = "cpu"

if args.save_file != False:
    save_path = args.save_dir+args.decoder_sd[0:args.decoder_sd.rfind("/")]+"/"+args.save_file
else:
    save_path = args.save_dir+args.decoder_sd[0:args.decoder_sd.rfind("/")]+"/"+datetime.now().strftime("%Y-%m-%d_%H:%M:%S")
if not os.path.exists(os.path.dirname(save_path)):
	os.makedirs(save_path)

items = []

if not args.decoder_sd:
    print ("No decoder state dictionary specified: provide the file name of the decoder trained model using the '--decoder-sd' argument")
    sys.exit(2)
else:
    decoder_sd = torch.load(args.decoder_dir+args.decoder_sd)
    args.action_dim = len(decoder_sd["fc21.bias"])
    decoder_module = importlib.import_module(args.models_dir + "." + args.decoder_model_file)
    decoder_model = decoder_module.VAE(args.action_dim).to(device)
    decoder_model.load_state_dict(decoder_sd)
    decoder_model.eval()

if "SLIDING_STATE" == args.encoder_sd.upper():
	args.state_dim = 2

if not args.encoder_sd:
    print ("No encoder state dictionary specified: provide the file name of the encoder trained model using the '--encoder-sd' argument")
    sys.exit(2)
elif args.encoder_sd.upper() not in ["DUMMY", "SLIDING_STATE"]:
    encoder_sd = torch.load(args.encoder_dir+args.encoder_sd)
    args.state_dim = len(encoder_sd["fc21.bias"])
    encoder_module = importlib.import_module(args.models_dir + "." + args.encoder_model_file)
    encoder_model = encoder_module.STATE_VAE(args.state_dim).to(device)
    encoder_model.load_state_dict(encoder_sd)
    encoder_model.eval()

if not args.algorithm:
    print ("No learning algorithm specified: provide the file name of the learning algorithm using the '--algorithm' argument")
    sys.exit(2)
else:
    algorithm_module = importlib.import_module(args.algorithm_dir + "." + args.algorithm)

if args.reward_type.upper() not in ["DISCRETE", "CONTINUOUS", "D", "C"]:
    print("argument --reward-type not valid")
    sys.exit(2)

sensing_script = importlib.import_module(args.sensing_script)
action_script = importlib.import_module(args.action_script)
image_reader_module = importlib.import_module(args.image_reader)
safety_check_module = importlib.import_module(args.safety_check_script)
trajectory_writer_module = importlib.import_module(args.trajectory_writer_script)

joint_names = [
    "panda_joint1",
    "panda_joint2",
    "panda_joint3",
    "panda_joint4",
    "panda_joint5",
    "panda_joint6",
    "panda_joint7"
]
joints_number = len(joint_names)

test = [
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40724661724585409,
			0.93545642930655959,
			-0.41933662556074763,
			-1.4320075802101837,
			0.44370802224428785,
			2.2730851050738083,
			-1.7492661652753791
		],
		[
			-0.40686069447372186,
			0.93503167806532927,
			-0.41935358529341654,
			-1.4328268111078344,
			0.44372688543624811,
			2.2734571413106877,
			-1.749170959547341
		],
		[
			-0.40608924687339976,
			0.93418337240293736,
			-0.41938741760523135,
			-1.4344627785476818,
			0.44376446326042446,
			2.2742001289034817,
			-1.7489798557695679
		],
		[
			-0.40493305863438928,
			0.93291388146917054,
			-0.41943794275546026,
			-1.4369105556741588,
			0.44382046286013443,
			2.2753119914219435,
			-1.7486914157966764
		],
		[
			-0.40339315989283869,
			0.9312266155228287,
			-0.41950492075196244,
			-1.4401632556757227,
			0.44389494143925895,
			2.2767906938971234,
			-1.7483028266198442
		],
		[
			-0.4014710935840442,
			0.92912633846370429,
			-0.41958807464004227,
			-1.4442108328652283,
			0.44398661937399686,
			2.2786311796249268,
			-1.7478118618396663
		],
		[
			-0.39916868634492775,
			0.92661865203210891,
			-0.41968690581791335,
			-1.4490417039825307,
			0.4440951265011287,
			2.280829054149748,
			-1.7472146206952022
		],
		[
			-0.39648804374700342,
			0.92371021184399649,
			-0.41980089391078762,
			-1.4546420562878619,
			0.44421964993469759,
			2.2833786782970282,
			-1.7465067683611739
		],
		[
			-0.3934315260899911,
			0.92040859320190183,
			-0.41992943756774276,
			-1.4609961617541256,
			0.44435925462994985,
			2.2862736308173308,
			-1.745683309248002
		],
		[
			-0.39000170803605783,
			0.91672221451971869,
			-0.42007185792899071,
			-1.4680865343552967,
			0.44451289001368999,
			2.2895067720895068,
			-1.7447386125629567
		],
		[
			-0.38620133568171516,
			0.91266025650125338,
			-0.42022740221591798,
			-1.4758940963849652,
			0.44467939692886677,
			2.2930703113473272,
			-1.7436664392255914
		],
		[
			-0.38203328202147468,
			0.90823257906516652,
			-0.4203952473340179,
			-1.4843983498030173,
			0.4448575147056783,
			2.296955875768405,
			-1.7424599694587952
		],
		[
			-0.37750050171783106,
			0.90344963791977706,
			-0.42057450338382091,
			-1.4935775487860301,
			0.44504588818272978,
			2.3011545798372568,
			-1.7411118304120625
		],
		[
			-0.37260598602365547,
			0.89832240254227791,
			-0.42076421698418182,
			-1.5034088699551806,
			0.44524307451817186,
			2.3056570935175911,
			-1.7396141232293312
		],
		[
			-0.36735271861326901,
			0.89286227712243027,
			-0.42096337432407194,
			-1.5138685771453404,
			0.44544754965160549,
			2.3104537079301486,
			-1.737958449046181
		],
		[
			-0.36174363297451501,
			0.88708102580584869,
			-0.42117090387246342,
			-1.5249321780303571,
			0.44565771430132262,
			2.3155343974191096,
			-1.7361359334851771
		],
		[
			-0.35578157190305465,
			0.88099070333111873,
			-0.42138567869011273,
			-1.5365745704030718,
			0.44587189940672939,
			2.3208888770900415,
			-1.7341372493087612
		],
		[
			-0.34946924952814085,
			0.87460359191127313,
			-0.42160651830131707,
			-1.5487701763982566,
			0.44608837095128229,
			2.3265066551049371,
			-1.7319526369819629
		],
		[
			-0.34280921619168359,
			0.86793214497477067,
			-0.42183219009740941,
			-1.5614930634198325,
			0.44630533412588647,
			2.332377079215556,
			-1.7295719229884661
		],
		[
			-0.33580382640364381,
			0.8609889381625182,
			-0.42206141025641619,
			-1.5747170509735113,
			0.44652093681568583,
			2.3384893771981923,
			-1.7269845358304912
		],
		[
			-0.32845521000979816,
			0.85378662778191816,
			-0.42229284417464125,
			-1.5884158029996578,
			0.44673327241395849,
			2.3448326910158084,
			-1.7241795197233893
		],
		[
			-0.32076524663458256,
			0.84633791675011627,
			-0.42252510641577246,
			-1.6025629056412833,
			0.44694038198513808,
			2.3513961046742051,
			-1.7211455460686629
		],
		[
			-0.31273554340304055,
			0.83865552791817466,
			-0.42275676019144132,
			-1.6171319306651442,
			0.44714025581472139,
			2.3581686658560894,
			-1.7178709228538316
		],
		[
			-0.30436741590198835,
			0.8307521845557686,
			-0.42298631639403367,
			-1.6320964849800534,
			0.44733083439709925,
			2.3651394015106915,
			-1.714343602184321
		],
		[
			-0.29566187231088531,
			0.82264059769068842,
			-0.42321223220812532,
			-1.6474302468684237,
			0.44751000892335918,
			2.3722973276480888,
			-1.7105511862019336
		],
		[
			-0.28661960061664632,
			0.81433345993658568,
			-0.42343290933137323,
			-1.6631069896695134,
			0.44767562134018302,
			2.3796314536386896,
			-1.7064809316874849
		],
		[
			-0.27724095882250149,
			0.80584344540289876,
			-0.42364669183928688,
			-1.6791005937317545,
			0.44782546405844109,
			2.3871307813518867,
			-1.7021197536829591
		],
		[
			-0.26752596806770551,
			0.79718321525953051,
			-0.423851863731248,
			-1.6953850474933907,
			0.44795727939635177,
			2.3947842994864819,
			-1.6974542285023737
		],
		[
			-0.257474308590941,
			0.78836542852204994,
			-0.42404664619772825,
			-1.7119344385623216,
			0.44806875884748681,
			2.4025809734519852,
			-1.69247059653169
		],
		[
			-0.24708531849441112,
			0.77940275762779976,
			-0.42422919465105646,
			-1.7287229356538494,
			0.4481575422688408,
			2.4105097311570587,
			-1.6871547652478451
		],
		[
			-0.23635799529650456,
			0.77030790838605312,
			-0.42439759556461326,
			-1.7457247622152148,
			0.44822121708889234,
			2.4185594450517649,
			-1.6814923129163661
		],
		[
			-0.22529100029751364,
			0.76109364390361756,
			-0.42454986316811677,
			-1.762914162523755,
			0.44825731764039117,
			2.4267189107562861,
			-1.6754684934570909
		],
		[
			-0.2138826658240863,
			0.75177281210842928,
			-0.42468393604997384,
			-1.7802653609961234,
			0.44826332472766151,
			2.4349768225924637,
			-1.669068242998998
		],
		[
			-0.202131005463071,
			0.74235837651571501,
			-0.42479767372164218,
			-1.7977525153933394,
			0.44823666554368558,
			2.443321746317622,
			-1.6622761886786015
		],
		[
			-0.19003372744327957,
			0.73286344990223995,
			-0.4248888532037946,
			-1.8153496645541702,
			0.44817471405817971,
			2.4517420893442967,
			-1.6550766602721803
		],
		[
			-0.17758825137372175,
			0.72330133057267187,
			-0.42495516569992053,
			-1.8330306712401931,
			0.44807479200431277,
			2.4602260687158859,
			-1.6474537052902531
		],
		[
			-0.1647917285982361,
			0.71368554091676084,
			-0.42499421343002736,
			-1.8507691606324521,
			0.44793417059855162,
			2.4687616770980263,
			-1.6393911082030219
		],
		[
			-0.15164106647835568,
			0.70402986796593259,
			-0.42500350670542297,
			-1.8685384549837945,
			0.44775007313519744,
			2.4773366470394707,
			-1.6308724145073934
		],
		[
			-0.13813295696769345,
			0.69434840566213907,
			-0.42498046133534895,
			-1.8863115049043395,
			0.44751967860420022,
			2.485938413755151,
			-1.6218809603886475
		],
		[
			-0.12426390989104937,
			0.68465559854978608,
			-0.42492239646754515,
			-1.9040608177414469,
			0.44724012648748412,
			2.4945540766885408,
			-1.6123999087715537
		],
		[
			-0.11003029138838329,
			0.67496628659269919,
			-0.4248265329778349,
			-1.9217583835110035,
			0.44690852289468336,
			2.5031703601206861,
			-1.6024122925947875
		],
		[
			-0.095428368026116817,
			0.66529575080211367,
			-0.42468999253851336,
			-1.9393755988446966,
			0.44652194820333491,
			2.5117735731098367,
			-1.5919010661764659
		],
		[
			-0.080454357113822095,
			0.65565975933827669,
			-0.42450979751180884,
			-1.9568831894387297,
			0.44607746637026224,
			2.5203495690684368,
			-1.5808491655644041
		],
		[
			-0.065104483790737341,
			0.64607461371743058,
			-0.42428287183285862,
			-1.9742511315236468,
			0.44557213607922647,
			2.5288837053135174,
			-1.5692395787785476
		],
		[
			-0.049375045460687828,
			0.63655719471781469,
			-0.42400604306642176,
			-1.9914485729226008,
			0.44500302388367102,
			2.5373608029620174,
			-1.5570554268503818
		],
		[
			-0.033262484152383281,
			0.62712500753319111,
			-0.42367604584268637,
			-2.0084437543264522,
			0.44436721949120456,
			2.5457651075838785,
			-1.5442800565396257
		],
		[
			-0.016763467360596186,
			0.61779622567089232,
			-0.42328952689961136,
			-2.0252039314879844,
			0.44366185331679509,
			2.5540802510724143,
			-1.5308971455560108
		],
		[
			0.00012502212209667511,
			0.60858973303448338,
			-0.42284305198162997,
			-2.0416952991232162,
			0.44288411640283198,
			2.5622892152423935,
			-1.516890821026506
		],
		[
			0.017405586948600026,
			0.59952516357010199,
			-0.42233311486639646,
			-2.057882917403715,
			0.44203128276440284,
			2.5703742977203063,
			-1.5022457918182706
		],
		[
			0.035080306211125206,
			0.59062293779229624,
			-0.42175614881125439,
			-2.073730642027602,
			0.44110073416562379,
			2.5783170807466784,
			-1.4869474951468844
		],
		[
			0.053150616511014333,
			0.58190429544210631,
			-0.4211085407276291,
			-2.0892010589652563,
			0.44008998726595605,
			2.5860984035647663,
			-1.4709822576596614
		],
		[
			0.071617183125046183,
			0.57339132347033661,
			-0.42038664840237577,
			-2.1042554250842054,
			0.43899672299282716,
			2.59369833912077,
			-1.4543374708771508
		],
		[
			0.090479761533135084,
			0.56510697848624702,
			-0.41958682108749579,
			-2.1188536159606404,
			0.43781881789777921,
			2.6010961758443298,
			-1.4370017804952095
		],
		[
			0.10973704986924251,
			0.55707510277096439,
			-0.41870542377013292,
			-2.1329540822752802,
			0.43655437713786566,
			2.6082704053103938,
			-1.4189652885899366
		],
		[
			0.12938653320780799,
			0.5493204329312078,
			-0.41773886540932603,
			-2.1465138162601827,
			0.4352017685933664,
			2.6151987165997146,
			-1.4002197672257384
		],
		[
			0.14942432100044145,
			0.54186860026878947,
			-0.41668363137991055,
			-2.1594883297003169,
			0.43375965748995188,
			2.6218579981698187,
			-1.3807588813442118
		],
		[
			0.16984497942682691,
			0.53474612197180305,
			-0.41553632029213489,
			-2.1718316449872832,
			0.4322270407428872,
			2.6282243480151313,
			-1.3605784181149061
		],
		[
			0.19064136091012168,
			0.52798038230207678,
			-0.41429368525259092,
			-2.1834963006592032,
			0.4306032800897725,
			2.6342730928277351,
			-1.3396765191715883
		],
		[
			0.21180443355590842,
			0.5215996030681892,
			-0.41295267949295106,
			-2.1944333727262522,
			0.42888813293595657,
			2.6399788167623504,
			-1.3180539113603089
		],
		[
			0.23332311378455295,
			0.51563280284178281,
			-0.41151050611362305,
			-2.2045925128607506,
			0.4270817797148474,
			2.6453154002543542,
			-1.2957141308181475
		],
		[
			0.25518410591344826,
			0.51010974460420966,
			-0.40996467146742754,
			-2.2139220042098073,
			0.42518484647753152,
			2.6502560691323849,
			-1.2726637344230132
		],
		[
			0.27737175287651777,
			0.50506087180626735,
			-0.40831304144439112,
			-2.2223688351542927,
			0.4231984213871699,
			2.6547734540030987,
			-1.2489124919532177
		],
		[
			0.29986790260746871,
			0.50051723318956343,
			-0.40655389961737792,
			-2.2298787907801905,
			0.4211240638183027,
			2.6588396595625849,
			-1.2244735517263055
		],
		[
			0.32265179482203332,
			0.49651039715468182,
			-0.40468600587948977,
			-2.2363965611408125,
			0.41896380486239732,
			2.6624263431069695,
			-1.1993635721103637
		],
		[
			0.34569997297414123,
			0.49307235696584883,
			-0.40270865386424054,
			-2.2418658645704399,
			0.41672013822772508,
			2.6655048010771187,
			-1.1736028111794568
		],
		[
			0.36898622599617525,
			0.49023542864722591,
			-0.40062172511151828,
			-2.2462295833673616,
			0.41439600079682209,
			2.668046061985788,
			-1.1472151669754249
		],
		[
			0.39248156403550216,
			0.4880321440409488,
			-0.39842573765578132,
			-2.24942990811053,
			0.41199474246315021,
			2.6700209835504225,
			-1.120228161388376
		],
		[
			0.41615423175047001,
			0.48649514214582751,
			-0.39612188650253144,
			-2.2514084857298764,
			0.40952008529500272,
			2.6714003513046665,
			-1.0926728616077017
		],
		[
			0.43996976182500097,
			0.48565706251935664,
			-0.39371207336178587,
			-2.2521065652431527,
			0.40697607254420282,
			2.6721549754027194,
			-1.0645837344309592
		],
		[
			0.46389107021442966,
			0.48555044518335538,
			-0.39119892305833925,
			-2.2514651338340652,
			0.40436700849548524,
			2.6722557817803119,
			-1.0359984304267491
		],
		[
			0.4878785932762984,
			0.48620764210474215,
			-0.38858578426638679,
			-2.2494250347102041,
			0.40169739059916987,
			2.6716738933109228,
			-1.0069574969750652
		],
		[
			0.51189046541522532,
			0.48766074591056413,
			-0.38587671263634837,
			-2.2459270569740273,
			0.39897183570217348,
			2.6703806961092957,
			-0.97750402146696469
		],
		[
			0.53588273424122956,
			0.4899415420305786,
			-0.38307643499238742,
			-2.2409119865844769,
			0.39619500245126354,
			2.6683478856934406,
			-0.9476832083179848
		],
		[
			0.560145881506244,
			0.49238217574137966,
			-0.38063920269529511,
			-2.2345052169388619,
			0.39289219330305164,
			2.6650440249221057,
			-0.9172075862170912
		],
		[
			0.58548118969463003,
			0.49300934515668104,
			-0.3798063396444249,
			-2.227189906838984,
			0.38774466412646624,
			2.6590134840756434,
			-0.88528742241847125
		],
		[
			0.61073332490853294,
			0.49324141398947374,
			-0.37958043198555391,
			-2.218658659663344,
			0.38182396404463559,
			2.6513535841872571,
			-0.85310542038507065
		],
		[
			0.63530439828491347,
			0.49436055493793146,
			-0.379113297380963,
			-2.2085578059047588,
			0.37600175397284286,
			2.6429814097596429,
			-0.82122510703473051
		],
		[
			0.65916301958471679,
			0.49637465272087833,
			-0.37840201066929929,
			-2.1968890584925855,
			0.37030679337108102,
			2.6339070408507781,
			-0.78970043928032552
		],
		[
			0.68228295124652549,
			0.4992907993700888,
			-0.37744727866041933,
			-2.1836541426856457,
			0.36476403829268023,
			2.6241401140909733,
			-0.75857913174438063
		],
		[
			0.70464287798334047,
			0.50311540267561472,
			-0.37625315415928201,
			-2.1688543974792314,
			0.35939443058692616,
			2.6136895759812657,
			-0.72790239404202817
		]
	]
test2 = []
for point in test:
    test2.extend(point)

state_trajectory_raw = [
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.40027911454373782,
		0.93548593130916302,
		-0.42683719346722948,
		-1.4389933668440875,
		0.47369998613317199,
		2.2887031662468549,
		-1.7686069190824814
	],
	[
		-0.39980332232353899,
		0.93497187169608265,
		-0.42685621313509248,
		-1.439986134016318,
		0.47372916515771518,
		2.289156343766491,
		-1.7684992608020293
	],
	[
		-0.39885232373277318,
		0.93394550280335076,
		-0.42689413349131405,
		-1.4419680136895034,
		0.4737872845378554,
		2.2900611291512698,
		-1.7682828739539944
	],
	[
		-0.39742727382868831,
		0.93241028419768657,
		-0.42695070367662002,
		-1.4449317972035143,
		0.4738738824806179,
		2.2914145302188822,
		-1.7679555473688755
	],
	[
		-0.39552953893158538,
		0.93037121055662431,
		-0.42702571804634254,
		-1.4488675186048978,
		0.47398889248289966,
		2.2932139363752149,
		-1.7675129649220087
	],
	[
		-0.3931617131158251,
		0.92783514333062467,
		-0.42711846428779998,
		-1.4537603817281197,
		0.47413070552324255,
		2.2954515778577065,
		-1.7669518400818633
	],
	[
		-0.39032628214226694,
		0.92481022926090539,
		-0.42722840598677431,
		-1.4595936551676132,
		0.47429855260848303,
		2.2981214403708443,
		-1.7662661496681129
	],
	[
		-0.38702628845608855,
		0.92130607101969664,
		-0.42735480719644714,
		-1.4663473696264919,
		0.47449118415062347,
		2.3012155172687052,
		-1.7654492996472222
	],
	[
		-0.38326511148275205,
		0.9173335496757502,
		-0.42749681974914383,
		-1.4739988890679712,
		0.47470716733235874,
		2.3047247328455573,
		-1.7644937083269394
	],
	[
		-0.37904639815279628,
		0.91290469803892071,
		-0.42765348897552713,
		-1.4825231727504258,
		0.47494489759012526,
		2.3086390465939921,
		-1.7633908509388401
	],
	[
		-0.37437399000982047,
		0.9080325691995722,
		-0.42782375955073454,
		-1.4918930479325996,
		0.47520261036431649,
		2.3129475613693691,
		-1.7621313057502574
	],
	[
		-0.36925184871857808,
		0.90273110397100786,
		-0.42800648128151009,
		-1.5020794857785393,
		0.47547839273572007,
		2.3176386323897318,
		-1.7607048003686867
	],
	[
		-0.36368398165302807,
		0.89701500065036177,
		-0.42820041466581094,
		-1.5130518735789029,
		0.47577019460303155,
		2.3226999742393755,
		-1.7591002570203853
	],
	[
		-0.3576743690529518,
		0.89089959011140496,
		-0.42840423608157624,
		-1.5247782772136262,
		0.47607583910197626,
		2.3281187633736495,
		-1.7573058357436671
	],
	[
		-0.35122689401243129,
		0.88440071876895454,
		-0.42861654249038877,
		-1.5372256887343578,
		0.47639303201964806,
		2.3338817340113378,
		-1.7553089746250543
	],
	[
		-0.34434527632216466,
		0.87753464144584181,
		-0.42883585557261006,
		-1.5503602549694606,
		0.4767193700141521,
		2.3399752657186252,
		-1.753096426409718
	],
	[
		-0.33703301094640559,
		0.87031792566230837,
		-0.42906062524140337,
		-1.5641474840841518,
		0.47705234750608738,
		2.346385461408488,
		-1.7506542910248521
	],
	[
		-0.32929331168755288,
		0.86276736838097468,
		-0.42928923251250234,
		-1.5785524280095005,
		0.47738936216203448,
		2.3530982148791768,
		-1.747968043756204
	],
	[
		-0.32112906038715772,
		0.85489992579805696,
		-0.42951999173363703,
		-1.5935398395463132,
		0.47772771893907739,
		2.3600992673789416,
		-1.7450225590069084
	],
	[
		-0.31254276183814206,
		0.84673265638638773,
		-0.42975115220157956,
		-1.6090743037268103,
		0.47806463270229022,
		2.367374253000508,
		-1.7418021297395234
	],
	[
		-0.30353650444310615,
		0.83828267707470971,
		-0.42998089921563104,
		-1.6251203436645489,
		0.47839722946354085,
		2.3749087329723686,
		-1.7382904828545522
	],
	[
		-0.29411192654901325,
		0.82956713219206923,
		-0.4302073546340569,
		-1.6416425016380782,
		0.47872254632004274,
		2.3826882191236556,
		-1.7344707908915966
	],
	[
		-0.28427018831858342,
		0.82060317461332299,
		-0.43042857701476123,
		-1.658605396541234,
		0.47903753019531914,
		2.3906981869572603,
		-1.7303256805538945
	],
	[
		-0.27401194896131414,
		0.81140795840592561,
		-0.4306425614337871,
		-1.6759737591040071,
		0.47933903550450802,
		2.3989240788768074,
		-1.7258372386559238
	],
	[
		-0.26333734913924045,
		0.80199864219186612,
		-0.43084723908545841,
		-1.693712446457198,
		0.47962382088127509,
		2.4073512981831997,
		-1.7209870161800549
	],
	[
		-0.25224599838103184,
		0.79239240239326225,
		-0.43104047677663632,
		-1.7117864376983307,
		0.47988854511615292,
		2.4159651944928315,
		-1.7157560312055316
	],
	[
		-0.24073696737937303,
		0.78260645551706176,
		-0.43122007643503396,
		-1.7301608121326024,
		0.48012976246704975,
		2.424751041239428,
		-1.7101247715448551
	],
	[
		-0.22880878510762415,
		0.77265808864507546,
		-0.43138377475816564,
		-1.7488007118274729,
		0.48034391751310018,
		2.4336940059118,
		-1.7040731979923951
	],
	[
		-0.21645944076958346,
		0.76256469732247734,
		-0.43152924313550944,
		-1.7676712900480271,
		0.48052733973403067,
		2.4427791136571253,
		-1.6975807491608512
	],
	[
		-0.2036863906883552,
		0.75234383007408101,
		-0.43165408798193006,
		-1.7867376470458141,
		0.48067623800975651,
		2.4519912048494725,
		-1.6906263489555771
	],
	[
		-0.19048657034475905,
		0.7420132388171492,
		-0.43175585162526381,
		-1.8059647545681792,
		0.4807866952499027,
		2.4613148871912056,
		-1.6831884178169827
	],
	[
		-0.17685641189067733,
		0.73159093447728796,
		-0.43183201389498405,
		-1.8253173703478156,
		0.48085466338116251,
		2.4707344828851432,
		-1.6752448889484779
	],
	[
		-0.16279186758672809,
		0.72109524714589557,
		-0.43187999456161752,
		-1.8447599437314646,
		0.48087595894253715,
		2.4802339713913595,
		-1.666773230842586
	],
	[
		-0.14828843974527051,
		0.71054489014044186,
		-0.43189715677743812,
		-1.8642565135189597,
		0.48084625956517968,
		2.4897969282676677,
		-1.6577504775206933
	],
	[
		-0.13334121789750628,
		0.69995902733985615,
		-0.43188081166710368,
		-1.8837705990143314,
		0.48076110164522057,
		2.4994064605894,
		-1.6481532680113509
	],
	[
		-0.11794492404552104,
		0.68935734316448272,
		-0.43182822421126954,
		-1.9032650852438218,
		0.48061587955492302,
		2.5090451394544653,
		-1.6379578967058854
	],
	[
		-0.10209396700429646,
		0.67876011455210172,
		-0.43173662055546341,
		-1.9227021032745388,
		0.48040584677994624,
		2.5186949301054309,
		-1.6271403763447765
	],
	[
		-0.08578250698179439,
		0.66818828424729459,
		-0.43160319685924237,
		-1.9420429065748464,
		0.4801261194181356,
		2.5283371202429241,
		-1.6156765154986816
	],
	[
		-0.069004531683101417,
		0.65766353467078942,
		-0.4314251297750647,
		-1.9612477443952039,
		0.47977168252765845,
		2.5379522471650424,
		-1.603542012507208
	],
	[
		-0.051753945351622539,
		0.64720836156833528,
		-0.43119958861069857,
		-1.9802757332173542,
		0.4793373998682639,
		2.5475200244462468,
		-1.5907125679173733
	],
	[
		-0.034024672269143276,
		0.63684614655608396,
		-0.43092374918143694,
		-1.9990847274209409,
		0.47881802763724446,
		2.5570192689665507,
		-1.5771640175105877
	],
	[
		-0.015810776317688898,
		0.62660122758282033,
		-0.43059480929733407,
		-2.0176311904494568,
		0.47820823285842923,
		2.5664278292170719,
		-1.5628724880073723
	],
	[
		0.0028934017523719992,
		0.61649896622122791,
		-0.43021000575474561,
		-2.0358700679203996,
		0.47750261713433595,
		2.5757225159400607,
		-1.547814577475435
	],
	[
		0.022093087716329791,
		0.60656581058407544,
		-0.42976663261021203,
		-2.0537546643146869,
		0.47669574651273733,
		2.5848790363077083,
		-1.5319675623182138
	],
	[
		0.041792896384241503,
		0.5968293525416003,
		-0.42926206040870185,
		-2.0712365250930298,
		0.47578218824200752,
		2.5938719330009792,
		-1.5153096324635653
	],
	[
		0.061996631855186383,
		0.58731837779955531,
		-0.42869375591977826,
		-2.0882653263150388,
		0.47475655518489607,
		2.6026745297118641,
		-1.4978201559788593
	],
	[
		0.082707064439222669,
		0.57806290729119558,
		-0.42805930180890284,
		-2.1047887740704634,
		0.47361355861579474,
		2.611258884752647,
		-1.4794799737802509
	],
	[
		0.10392568360260385,
		0.56909422825053513,
		-0.42735641554427517,
		-2.1207525162578573,
		0.47234807002747198,
		2.619595754604382,
		-1.4602717243504091
	],
	[
		0.12565242689093947,
		0.56044491327989332,
		-0.42658296672318685,
		-2.1361000694469636,
		0.47095519240284994,
		2.6276545693615567,
		-1.4401801974019794
	],
	[
		0.14788538557445255,
		0.55214882571533752,
		-0.42573699191041592,
		-2.1507727637156893,
		0.46943034114742821,
		2.6354034221158598,
		-1.4191927141995373
	],
	[
		0.1706204887591781,
		0.5442411096440245,
		-0.42481670603293314,
		-2.1647097084344318,
		0.46776933451008962,
		2.6428090743510224,
		-1.3972995307654308
	],
	[
		0.19385116892936907,
		0.53675816305383028,
		-0.4238205093911695,
		-2.1778477819489743,
		0.46596849282831909,
		2.6498369793724104,
		-1.3744942584435615
	],
	[
		0.21756801332783571,
		0.52973759281468691,
		-0.42274698944975464,
		-2.1901216479531405,
		0.46402474530769028,
		2.6564513256462252,
		-1.3507742942989376
	],
	[
		0.24175840722115211,
		0.52321815051945131,
		-0.4215949167804271,
		-2.2014638010056906,
		0.46193574228459688,
		2.6626151016501889,
		-1.3261412516367115
	],
	[
		0.26640617688878226,
		0.51723964866483652,
		-0.42036323486189431,
		-2.2118046430928389,
		0.45969997003998897,
		2.6682901834162167,
		-1.3006013786135864
	],
	[
		0.29149124203997034,
		0.51184285724233636,
		-0.41905104389961234,
		-2.2210725923295187,
		0.45731686426581825,
		2.6734374453547369,
		-1.2741659506088225
	],
	[
		0.31698928918352548,
		0.50706938154296932,
		-0.41765757940006359,
		-2.2291942237947033,
		0.454786917295666,
		2.6780168941733757,
		-1.246851619886828
	],
	[
		0.3428714790982168,
		0.50296152285961315,
		-0.41618218688425118,
		-2.2360944410825732,
		0.45211177328561131,
		2.681987824731392,
		-1.218680704325483
	],
	[
		0.3691042027840083,
		0.49956212479089596,
		-0.4146242947931057,
		-2.241696675408781,
		0.44929430478700499,
		2.6853089955086622,
		-1.1896813958443446
	],
	[
		0.39564890089939386,
		0.49691440899586237,
		-0.41298338823753122,
		-2.245923107043565,
		0.44633866372568065,
		2.6879388200313894,
		-1.1598878689009275
	],
	[
		0.42248230091139455,
		0.49502596244336367,
		-0.41128527886208394,
		-2.248704931010526,
		0.44322296890518276,
		2.6898101281864308,
		-1.1293204810535615
	],
	[
		0.44979303539120313,
		0.49351604482493938,
		-0.40983911616073287,
		-2.2500806730585698,
		0.439631440202847,
		2.6905796956076209,
		-1.0977939273717783
	],
	[
		0.47759139204920237,
		0.49228110743252285,
		-0.40873832153202605,
		-2.2500094958961832,
		0.43546092246393947,
		2.690102617849957,
		-1.06528713798219
	],
	[
		0.50533516599339923,
		0.49139349324883674,
		-0.40795619124878241,
		-2.2484414834103741,
		0.43081702084302176,
		2.6883902433037652,
		-1.0324110295844215
	],
	[
		0.5310927541815943,
		0.49127813706255763,
		-0.40719953751623778,
		-2.2454898173793367,
		0.42633814988096536,
		2.6859446261755795,
		-1.0014360721451572
	],
	[
		0.55468711883946109,
		0.49189062450713583,
		-0.40640220339165373,
		-2.2414320078423464,
		0.42215907720378321,
		2.6830114280986281,
		-0.97265541900145336
	],
	[
		0.57607070939634719,
		0.49306967846898259,
		-0.40558421484785062,
		-2.2365773037071373,
		0.41831462748927595,
		2.6797528325030644,
		-0.94622335254619339
	],
	[
		0.59525513777106909,
		0.49465899111545281,
		-0.40476599293480331,
		-2.2312185137148539,
		0.41482384156559116,
		2.676319577033202,
		-0.92221701669863565
	]
]

state_trajectory = []
for point in state_trajectory_raw:
    state_trajectory.extend(point)

# ========== a200_b01_mc ==========
a200_b01_mc_latent_space_means = [-0.95741573,  0.60835766,  0.03808778, -0.70411791,  0.15081754]
mc_latent_space_stds = [0.14915584, 0.77813671, 0.15265675, 0.17448557, 0.12238263]
mc_best_mean = [-0.9914,  0.7875,  0.0775, -0.6818,  0.1817]
mc_best_std = [0.0538, 0.0181, 0.3415, 0.0175, 0.2323]
mc_best_mean_faster = [-1.0914,  1.0875,  0.0775, -0.5818,  0.1817]
mc_fastest = [-1.2, 1.9, 0.3, -0.4, 0.4]

test_action = [-0.79844596, -0.63713676, -0.12888897, -0.97707188,  0.01480127]

a200_b01_mc_13_means = [-0.79844596, -0.23713676, -0.12888897, -0.87707188,  0.01480127]
a200_b01_mc_14_means = [-0.8877851 ,  0.24533824, -0.02885615, -0.79018154,  0.09704519]
a200_b01_mc_15_means = [-0.97981189,  0.71057909,  0.05748677, -0.69583368,  0.17542016]
a200_b01_mc_16_means = [-1.0606842 ,  1.14844979,  0.14893559, -0.59407567,  0.23862324]
a200_b01_mc_17_means = [-1.13784433,  1.55074548,  0.22355699, -0.49421183,  0.28466991]
a200_b01_mc_18_means = [-1.1728737 ,  1.76443983,  0.26582965, -0.45975538,  0.30441109]

a200_b01_initial_means = [a200_b01_mc_13_means] + [a200_b01_mc_14_means] + [a200_b01_mc_15_means] + [a200_b01_mc_16_means] + [a200_b01_mc_17_means] + [a200_b01_mc_18_means]
a200_b01_reversed_initial_means = [a200_b01_mc_18_means] + [a200_b01_mc_17_means] + [a200_b01_mc_16_means] + [a200_b01_mc_15_means] + [a200_b01_mc_14_means] + [a200_b01_mc_13_means]
a200_b01_shuffled_initial_means = [a200_b01_mc_18_means] + [a200_b01_mc_15_means] + [a200_b01_mc_13_means] + [a200_b01_mc_17_means] + [a200_b01_mc_14_means] + [a200_b01_mc_16_means]

# ========== a100_b001_mc ==========
a100_b001_mc_latent_space_means = [-2.4141, -3.1220,  1.2711,  0.9376,  1.6012]

a100_b001_mc_12_means = [-2.1728, -2.6527,  1.1599,  0.3008,  1.9964]
a100_b001_mc_13_means = [-2.2477, -2.7988,  1.1962,  0.5003,  1.8728]
a100_b001_mc_14_means = [-2.3427, -2.9834,  1.2388,  0.7525,  1.7158]
a100_b001_mc_15_means = [-2.4349, -3.1625,  1.2817,  0.9947,  1.5658]
a100_b001_mc_16_means = [-2.5211, -3.3298,  1.3201,  1.2193,  1.4266]
a100_b001_mc_17_means = [-2.5993, -3.4820,  1.3547,  1.4220,  1.3003]
a100_b001_mc_18_means = [-2.6392, -3.5588,  1.3718,  1.5257,  1.2370]

a100_b001_initial_means = [a100_b001_mc_13_means] + [a100_b001_mc_14_means] + [a100_b001_mc_15_means] + [a100_b001_mc_16_means] + [a100_b001_mc_17_means] + [a100_b001_mc_18_means]
a100_b001_reversed_initial_means = [a100_b001_mc_18_means] + [a100_b001_mc_17_means] + [a100_b001_mc_16_means] + [a100_b001_mc_15_means] + [a100_b001_mc_14_means] + [a100_b001_mc_13_means]
a100_b001_shuffled_initial_means = [a100_b001_mc_17_means] + [a100_b001_mc_15_means] + [a100_b001_mc_13_means] + [a100_b001_mc_18_means] + [a100_b001_mc_14_means] + [a100_b001_mc_16_means]


# ========== a200_b01_10000e_mc ==========
a200_b01_10000e_mc_latent_space_means = [0.0260, 0.0046, 0.0036, 0.0586, 0.0040]
a200_b01_10000e_mc_latent_space_stds = [0.9983, 1.0437, 1.0033, 0.9555, 0.9893]

a200_b01_10000e_mc_12_means = [ 0.0070, -1.6013, -0.0356,  0.6396,  0.0168]
a200_b01_10000e_mc_13_means = [ 0.0063, -1.1037,  0.0251,  0.1639,  0.0351]
a200_b01_10000e_mc_14_means = [ 0.0502, -0.4833, -0.0348, -0.0588, -0.0115]
a200_b01_10000e_mc_15_means = [ 0.0277,  0.1102,  0.0260, -0.0783, -0.0032]
a200_b01_10000e_mc_16_means = [0.0413, 0.6655, 0.0220, 0.0987, 0.0118]
a200_b01_10000e_mc_17_means = [ 0.0274,  1.2638,  0.0055,  0.0380, -0.0135]
a200_b01_10000e_mc_18_means = [-4.7113e-03,  1.6995e+00,  1.2287e-04, -5.7070e-01, -1.5765e-02]

a200_b01_10000e_mc_12_stds = [1.0318, 0.2006, 1.0162, 0.8498, 0.9931]
a200_b01_10000e_mc_13_stds = [1.0135, 0.2658, 1.0060, 0.8723, 0.9812]
a200_b01_10000e_mc_14_stds = [0.9669, 0.2571, 1.0099, 0.9603, 0.9775]
a200_b01_10000e_mc_15_stds = [1.0045, 0.2394, 0.9775, 0.9668, 0.9815]
a200_b01_10000e_mc_16_stds = [1.0096, 0.2401, 0.9847, 1.0167, 0.9816]
a200_b01_10000e_mc_17_stds = [0.9731, 0.3234, 1.0264, 0.9017, 1.0077]
a200_b01_10000e_mc_18_stds = [1.0058, 0.2461, 1.0151, 0.6494, 1.0328]

a200_b01_10000_initial_means = [a200_b01_10000e_mc_13_means] + [a200_b01_10000e_mc_14_means] + [a200_b01_10000e_mc_15_means] + [a200_b01_10000e_mc_16_means] + [a200_b01_10000e_mc_17_means] + [a200_b01_10000e_mc_18_means]
a200_b01_10000_reversed_initial_means = [a200_b01_10000e_mc_18_means] + [a200_b01_10000e_mc_17_means] + [a200_b01_10000e_mc_16_means] + [a200_b01_10000e_mc_15_means] + [a200_b01_10000e_mc_14_means] + [a200_b01_10000e_mc_13_means]
a200_b01_10000_shuffled_initial_means = [a200_b01_10000e_mc_17_means] + [a200_b01_10000e_mc_15_means] + [a200_b01_10000e_mc_13_means] + [a200_b01_10000e_mc_18_means] + [a200_b01_10000e_mc_14_means] + [a200_b01_10000e_mc_16_means]

			# WRONG
# # ========== a200_b001_20000e_mc ==========
# a200_b001_20000e_mc_latent_space_means = [0.0260, 0.0046, 0.0036, 0.0586, 0.0040]
# a200_b001_20000e_mc_latent_space_stds = [0.9983, 1.0437, 1.0033, 0.9555, 0.9893]

# a200_b001_20000e_mc_12_means = [ 0.0070, -1.6013, -0.0356,  0.6396,  0.0168]
# a200_b001_20000e_mc_13_means = [ 0.0063, -1.1037,  0.0251,  0.1639,  0.0351]
# a200_b001_20000e_mc_14_means = [ 0.0502, -0.4833, -0.0348, -0.0588, -0.0115]
# a200_b001_20000e_mc_15_means = [ 0.0277,  0.1102,  0.0260, -0.0783, -0.0032]
# a200_b001_20000e_mc_16_means = [0.0413, 0.6655, 0.0220, 0.0987, 0.0118]
# a200_b001_20000e_mc_17_means = [ 0.0274,  1.2638,  0.0055,  0.0380, -0.0135]
# a200_b001_20000e_mc_18_means = [-4.7113e-03,  1.6995e+00,  1.2287e-04, -5.7070e-01, -1.5765e-02]

# a200_b001_20000e_mc_12_stds = [1.0318, 0.2006, 1.0162, 0.8498, 0.9931]
# a200_b001_20000e_mc_13_stds = [1.0135, 0.2658, 1.0060, 0.8723, 0.9812]
# a200_b001_20000e_mc_14_stds = [0.9669, 0.2571, 1.0099, 0.9603, 0.9775]
# a200_b001_20000e_mc_15_stds = [1.0045, 0.2394, 0.9775, 0.9668, 0.9815]
# a200_b001_20000e_mc_16_stds = [1.0096, 0.2401, 0.9847, 1.0167, 0.9816]
# a200_b001_20000e_mc_17_stds = [0.9731, 0.3234, 1.0264, 0.9017, 1.0077]
# a200_b001_20000e_mc_18_stds = [1.0058, 0.2461, 1.0151, 0.6494, 1.0328]

# a200_b001_20000_initial_means = [a200_b001_20000e_mc_13_means] + [a200_b001_20000e_mc_14_means] + [a200_b001_20000e_mc_15_means] + [a200_b001_20000e_mc_16_means] + [a200_b001_20000e_mc_17_means] + [a200_b001_20000e_mc_18_means]
# a200_b001_20000_reversed_initial_means = [a200_b001_20000e_mc_18_means] + [a200_b001_20000e_mc_17_means] + [a200_b001_20000e_mc_16_means] + [a200_b001_20000e_mc_15_means] + [a200_b001_20000e_mc_14_means] + [a200_b001_20000e_mc_13_means]
# a200_b001_20000_shuffled_initial_means = [a200_b001_20000e_mc_17_means] + [a200_b001_20000e_mc_15_means] + [a200_b001_20000e_mc_13_means] + [a200_b001_20000e_mc_18_means] + [a200_b001_20000e_mc_14_means] + [a200_b001_20000e_mc_16_means]

# ========== a200_b01_20000e_ll ==========
a200_b01_20000e_ll_latent_space_means = [-1.1637,  0.2294,  0.0420, -0.7556,  0.0686]
a200_b01_20000e_ll_latent_space_stds = [0.3961, 0.8107, 0.8620, 0.2405, 0.8627]

a200_b01_20000e_ll_12_means = [-0.7074, -1.0712,  0.0902, -1.0058,  0.1459]
a200_b01_20000e_ll_13_means = [-0.8080, -0.6509,  0.0343, -0.9644,  0.0565]
a200_b01_20000e_ll_14_means = [-0.9603, -0.1414,  0.0279, -0.8642,  0.0750]
a200_b01_20000e_ll_15_means = [-1.1411,  0.3259,  0.0534, -0.7545,  0.0605]
a200_b01_20000e_ll_16_means = [-1.3661,  0.7623,  0.0516, -0.6385,  0.0577]
a200_b01_20000e_ll_17_means = [-1.6163,  1.2043,  0.0662, -0.5008,  0.0567]
a200_b01_20000e_ll_18_means = [-1.7591,  1.4994, -0.0889, -0.4661,  0.0474]

a200_b01_20000e_ll_12_stds = [0.1612, 0.1302, 0.7633, 0.1414, 0.7703]
a200_b01_20000e_ll_13_stds = [0.1761, 0.1917, 0.8106, 0.1521, 0.8370]
a200_b01_20000e_ll_14_stds = [0.1827, 0.1804, 0.8211, 0.1546, 0.8677]
a200_b01_20000e_ll_15_stds = [0.2068, 0.1634, 0.8613, 0.1584, 0.8594]
a200_b01_20000e_ll_16_stds = [0.2301, 0.1557, 0.9273, 0.1592, 0.8920]
a200_b01_20000e_ll_17_stds = [0.2641, 0.1737, 0.9165, 0.1665, 0.8952]
a200_b01_20000e_ll_18_stds = [0.2536, 0.1013, 0.9191, 0.1334, 0.9002]

a200_b01_20000_ll_initial_means = [a200_b01_20000e_ll_13_means] + [a200_b01_20000e_ll_14_means] + [a200_b01_20000e_ll_15_means] + [a200_b01_20000e_ll_16_means] + [a200_b01_20000e_ll_17_means] + [a200_b01_20000e_ll_18_means]
a200_b01_20000_ll_reversed_initial_means = [a200_b01_20000e_ll_18_means] + [a200_b01_20000e_ll_17_means] + [a200_b01_20000e_ll_16_means] + [a200_b01_20000e_ll_15_means] + [a200_b01_20000e_ll_14_means] + [a200_b01_20000e_ll_13_means]
a200_b01_20000_ll_shuffled_initial_means = [a200_b01_20000e_ll_17_means] + [a200_b01_20000e_ll_15_means] + [a200_b01_20000e_ll_13_means] + [a200_b01_20000e_ll_18_means] + [a200_b01_20000e_ll_14_means] + [a200_b01_20000e_ll_16_means]

# ========== a200_b001_20000e ==========
a200_b001_20000e_latent_space_means = [-1.7219,  1.0729, -0.1047, -1.6899,  0.3130]
a200_b001_20000e_latent_space_stds = [0.1073, 1.2100, 0.3984, 0.2595, 0.3141]

a200_b001_20000e_12_means = [-1.5408, -0.8342, -0.2943, -1.9800, -0.1611]
a200_b001_20000e_13_means = [-1.6170, -0.24982, -0.21604, -1.9177, -0.0015477]
a200_b001_20000e_14_means = [-1.7011,  0.4974, -0.1605, -1.8096,  0.1862]
a200_b001_20000e_15_means = [-1.7592,  1.2380, -0.0745, -1.6906,  0.3548]
a200_b001_20000e_16_means = [-1.7939,  1.9186, -0.0265, -1.5452,  0.5254]
a200_b001_20000e_17_means = [-1.8194,  2.5380,  0.0216, -1.4065,  0.6681]
a200_b001_20000e_18_means = [-1.8175,  2.8975,  0.0471, -1.3841,  0.6994]

a200_b001_20000e_12_stds = [0.0523, 0.1931, 0.3549, 0.1520, 0.1247]
a200_b001_20000e_13_stds = [0.0610, 0.2794, 0.3688, 0.1526, 0.1398]
a200_b001_20000e_14_stds = [0.0606, 0.2784, 0.3884, 0.1599, 0.1404]
a200_b001_20000e_15_stds = [0.0517, 0.2629, 0.3858, 0.1617, 0.1397]
a200_b001_20000e_16_stds = [0.0526, 0.2452, 0.3905, 0.1707, 0.1433]
a200_b001_20000e_17_stds = [0.0523, 0.2212, 0.4012, 0.1672, 0.1366]
a200_b001_20000e_18_stds = [0.0414, 0.1072, 0.3890, 0.1117, 0.0983]

a200_b001_20000_initial_means = [a200_b001_20000e_13_means] + [a200_b001_20000e_14_means] + [a200_b001_20000e_15_means] + [a200_b001_20000e_16_means] + [a200_b001_20000e_17_means] + [a200_b001_20000e_18_means]
a200_b001_20000_reversed_initial_means = [a200_b001_20000e_18_means] + [a200_b001_20000e_17_means] + [a200_b001_20000e_16_means] + [a200_b001_20000e_15_means] + [a200_b001_20000e_14_means] + [a200_b001_20000e_13_means]
a200_b001_20000_shuffled_initial_means = [a200_b001_20000e_17_means] + [a200_b001_20000e_15_means] + [a200_b001_20000e_13_means] + [a200_b001_20000e_18_means] + [a200_b001_20000e_14_means] + [a200_b001_20000e_16_means]

# ========== a200_b01_10000e_too_fast ==========
a200_b01_10000e_too_fast_latent_space_means = [-1.1826, -0.0662, -0.0697, -0.8120,  0.0305]
a200_b01_10000e_too_fast_latent_space_stds = [0.2744, 0.2454, 0.2452, 0.1368, 0.5081]

a200_b01_10000e_too_fast_17_means = [-0.8152,  0.0060, -0.1689, -0.9157,  0.7256]
a200_b01_10000e_too_fast_18_means = [-0.7959,  0.0349, -0.1959, -0.9898,  0.7883]
a200_b01_10000e_too_fast_19_means = [-0.9128,  0.0084, -0.1584, -0.9440,  0.5655]
a200_b01_10000e_too_fast_20_means = [-1.0634, -0.0176, -0.1007, -0.8691,  0.2605]
a200_b01_10000e_too_fast_21_means = [-1.2206, -0.0691, -0.0603, -0.7937, -0.0463]
a200_b01_10000e_too_fast_22_means = [-1.3617, -0.1189, -0.0196, -0.7266, -0.3216]
a200_b01_10000e_too_fast_23_means = [-1.4939, -0.1716,  0.0350, -0.6624, -0.5779]
a200_b01_10000e_too_fast_24_means = [-1.5595, -0.1616,  0.0558, -0.6396, -0.7130]

a200_b01_10000e_too_fast_17_stds = [0.1217, 0.2218, 0.2218, 0.0919, 0.1779]
a200_b01_10000e_too_fast_18_stds = [0.1204, 0.2367, 0.2245, 0.0695, 0.1477]
a200_b01_10000e_too_fast_19_stds = [0.1299, 0.2309, 0.2433, 0.0774, 0.1813]
a200_b01_10000e_too_fast_20_stds = [0.1243, 0.2357, 0.2364, 0.0723, 0.1677]
a200_b01_10000e_too_fast_21_stds = [0.1265, 0.2402, 0.2247, 0.0722, 0.1666]
a200_b01_10000e_too_fast_22_stds = [0.1256, 0.2362, 0.2336, 0.0757, 0.1682]
a200_b01_10000e_too_fast_23_stds = [0.1178, 0.2273, 0.2278, 0.0693, 0.1472]
a200_b01_10000e_too_fast_24_stds = [0.1037, 0.2391, 0.2293, 0.0615, 0.1116]


a200_b01_10000_too_fast_initial_means = [a200_b01_10000e_too_fast_17_means] + [a200_b01_10000e_too_fast_18_means] + [a200_b01_10000e_too_fast_19_means] + [a200_b01_10000e_too_fast_20_means] + [a200_b01_10000e_too_fast_21_means] + [a200_b01_10000e_too_fast_22_means]
a200_b01_10000_too_fast_reversed_initial_means = [a200_b01_10000e_too_fast_24_means] + [a200_b01_10000e_too_fast_23_means] + [a200_b01_10000e_too_fast_22_means] + [a200_b01_10000e_too_fast_21_means] + [a200_b01_10000e_too_fast_20_means] + [a200_b01_10000e_too_fast_19_means]
a200_b01_10000_too_fast_shuffled_initial_means = [a200_b01_10000e_too_fast_23_means] + [a200_b01_10000e_too_fast_21_means] + [a200_b01_10000e_too_fast_17_means] + [a200_b01_10000e_too_fast_24_means] + [a200_b01_10000e_too_fast_22_means] + [a200_b01_10000e_too_fast_18_means]


# ========== a100_b01_mc ==========
a100_b01_mc_latent_space_means = [ 0.5667, -0.6089,  1.9060,  0.1249,  3.5259]

a100_b01_mc_12_means = [ 0.5394, -0.3650,  0.9511,  1.0091,  3.5482]
a100_b01_mc_13_means = [ 0.5467, -0.4432,  1.2512,  0.7295,  3.5419]
a100_b01_mc_14_means = [ 0.5606, -0.5378,  1.6244,  0.3809,  3.5326]
a100_b01_mc_15_means = [ 0.5681, -0.6324,  1.9864,  0.0460,  3.5243]
a100_b01_mc_16_means = [ 0.5789, -0.7149,  2.3237, -0.2643,  3.5159]
a100_b01_mc_17_means = [ 0.5883, -0.7942,  2.6396, -0.5471,  3.5080]
a100_b01_mc_18_means = [ 0.5913, -0.8299,  2.8025, -0.6876,  3.5046]

a100_b01_initial_means = [a100_b01_mc_13_means] + [a100_b01_mc_14_means] + [a100_b01_mc_15_means] + [a100_b01_mc_16_means] + [a100_b01_mc_17_means] + [a100_b01_mc_18_means]
a100_b01_reversed_initial_means = [a100_b01_mc_18_means] + [a100_b01_mc_17_means] + [a100_b01_mc_16_means] + [a100_b01_mc_15_means] + [a100_b01_mc_14_means] + [a100_b01_mc_13_means]
a100_b01_shuffled_initial_means = [a100_b01_mc_17_means] + [a100_b01_mc_15_means] + [a100_b01_mc_13_means] + [a100_b01_mc_14_means] + [a100_b01_mc_16_means] + [a100_b01_mc_12_means]


mc_latent_space_means_b0 = [-2.3453495 ,  1.87199709,  0.66421834, -2.87626281,  1.57093551]
mc_latent_space_stds_b0 = [0.41007773, 1.01831094, 0.45268615, 0.01925819, 0.65967075]
mc_best_mean_b0 = [-1.5954519510269165, -0.0013902420178055763, -0.16062034666538239, -2.9057390689849854, 0.356065958738327]
mc_best_std_b0 = [0.008678837679326534, 0.016342472285032272, 0.016840659081935883, 0.004060306120663881, 0.00893393438309431]

vel_latent_space_means = [-1.54930503,  0.25162958,  0.05412535, -1.4289467 , -0.06778317]
vel_latent_space_stds = [0.42513496, 0.01628749, 0.06014936, 0.02778022, 0.51911289]
vel_best_mean = [-1.3671,  0.2444,  0.0290, -1.4391,  0.1555]
vel_best_std = [0.0204, 0.2391, 0.2653, 0.0247, 0.0492]

if args.latent_space_data != False:
    if args.latent_space_data == True or args.latent_space_data == "True":
        args.latent_space_data = "/latent_space_data.txt"
    with open(os.path.dirname(args.decoder_dir+args.decoder_sd)+args.latent_space_data, 'r') as f:
        latent_space_data = json.loads(f.read())
    initial_means = latent_space_data["mean"]
    initial_stds = latent_space_data["std"]
    actions = [(vel, latent_space_data["vel"][vel]["mean"]) for vel in latent_space_data["vel"]]
    actions.sort()  # slow to fast
    actions = [action[1] for action in actions]
    initial_actions = [actions[-4]] + [actions[0]] + [actions[-2]] + [actions[-3]]
    # initial_actions = [actions[-1]] + [actions[0]] + [actions[-2]] + [actions[-3]]
    initial_actions += random.sample(actions, args.batch_size)
else:
    initial_means = a200_b001_20000e_latent_space_means
    initial_stds = a200_b001_20000e_latent_space_stds
    initial_actions = a200_b001_20000_shuffled_initial_means

best_det_reward = None

state_data = None
if "SLIDING_STATE" == args.encoder_sd.upper():
	input_folder = package_path + "/sensing_data/slide_sensing/" + args.state_folder
	with open(input_folder+"/state_data.txt", 'r') as f:
		data = f.read()
	state_data = json.loads(data)
	state_data = ast.literal_eval(json.dumps(state_data))

def get_dummy_action(dim):
    # return torch.tensor([-1.0398e+00,  1.2563e+00,  8.3643e-02, -5.1169e-01,  1.4186e-01])
    return torch.zeros(dim)
    # return torch.randn(dim)
    # return torch.ones(dim)

def execute_action(input_folder, tot_time_nsecs, is_simulation, is_learning, t):
    trajectory_writer_module.talker(input_folder, tot_time_nsecs, is_simulation, is_learning, t)

def close_all(items):
    for item in items:
        item.close()

def get_angle(x, y):
    return (math.atan2(y, x)*180/math.pi + 360) % 360

def evaluate_board(image_reader=None, epoch=None, batch_index=None, repetition=None, label=None):
	while True:
		if epoch != None:
			dr_filename = "/dr_{}-e_{}-i_{}-r_{}-l.jpg".format(epoch, batch_index, repetition, label)
			cv_filename = "/cv_{}-e_{}-i_{}-r_{}-l.jpg".format(epoch, batch_index, repetition, label)
			distance, stone_x, stone_y = image_reader.evaluate_board(dr_save_path=os.path.dirname(save_path)+dr_filename, cv_save_path=os.path.dirname(save_path)+cv_filename)
		else:
			distance, stone_x, stone_y = image_reader.evaluate_board()
		if distance != -1:
			if args.reward_type.upper() in ["D", "DISCRETE"]:
				reward = max(0, 4 - distance//100)
			elif args.reward_type.upper() in ["C", "CONTINUOUS"]:
				reward = max(0, 4 - float(distance)/100)

			angle = get_angle(stone_x, stone_y)
			# if distance > 350:
			#     reward = 0
			# else:
			#     reward = (1-(distance/350.0))**2
			break
		else:
			command = raw_input("'c'=continue\n's'=set reward\n't'=try again\n'o'=out of bounds\n\nInput command: ")
			if "c" == command:
				break
			elif "s" == command:
				while True:
					try:
						r = raw_input("Set the reward: ")
						if "q" != r:
							reward = float(r)
							distance = "set"
							angle = "set"
						break
					except:
						print("INFO: Input 't' to try again evaluating the board")
						print("ERROR: The reward must be a float")
				break
			elif "o" == command:
				reward = 0
				distance = "out"
				angle = "out"
				break
			elif "xy" == command:
				stone_x = raw_input("Insert stone_x value: ")
				stone_y = raw_input("Insert stone_y value: ")
			elif "t" == command:
				pass
	return reward, distance, angle, stone_x, stone_y

def get_state(dim=args.state_dim, image_reader=None, trajectory_dict=None, decoder_model=None):
    if "DUMMY" == args.encoder_sd.upper():
        return torch.ones(dim)
    elif "SLIDING_STATE" == args.encoder_sd.upper():
		labels = [label for label in state_data]
		print("The available labels are:")
		for label in labels:
			print ("\t{}".format(label))
		command = raw_input("Select a label or leave blank to sense a new stone:\n> ")
		if command in labels:
			label = command
			x_t = torch.FloatTensor(state_data[label]["x"])
			y_t = torch.FloatTensor(state_data[label]["y"])
			x_mean = x_t.mean()
			x_std = x_t.std()
			y_mean = y_t.mean()
			y_std = y_t.std()
			mean_vector = torch.tensor([x_mean, y_mean])
			cov_matrix = torch.diag(torch.tensor([x_std**2, y_std**2]))
			dist = MultivariateNormal(mean_vector, cov_matrix)
			state = dist.sample()
			return state, label
		else:
			label = "sensed"
			decoded_trajectory = torch.tensor(state_trajectory)
			trajectory_dict["joint_trajectory"] = decoded_trajectory.view(100, -1).tolist()
			safety_res = safety_check_module.check(decoded_trajectory.tolist(), args.execution_time)
			if safety_res.is_safe:
				repetitions = 1
				state_x = 0
				state_y = 0
				for repetition in range(repetitions):
					print("Repetition {}/{}".format(repetition+1, repetitions))
					command = raw_input("Press enter to execute the action: ")
					if "skip" != command:
						execute_action(input_folder=False, tot_time_nsecs=args.execution_time, is_simulation=False, is_learning=True, t=trajectory_dict)
					command = raw_input("Press enter to evaluate the board\n")
					reward, distance, angle, stone_x, stone_y = evaluate_board(image_reader=image_reader)
					state_x += stone_x
					state_y += stone_y
				state_x = state_x / float(repetitions)
				state_y = state_y / float(repetitions)
				state = torch.tensor([state_x, state_y])
				return state, label
			else:
				print("Unsafe trajectory")
    else:
        sensors_data = sensing_script.sense_stone()
        forces_tensor = []
        forces_tensor.append(sensors_data["force"]["x"][-1])
        forces_tensor.append(sensors_data["force"]["y"][-1])
        forces_tensor.append(sensors_data["force"]["z"][-1])
        forces_tensor.append(sensors_data["torque"]["x"][-1])
        forces_tensor.append(sensors_data["torque"]["y"][-1])
        forces_tensor.append(sensors_data["torque"]["z"][-1])
        state_mu, state_logvar = encoder_model.encode(torch.tensor(forces_tensor).view(-1, 600))
        state_mu = state_mu[0].detach()
        return state_mu
    # return torch.randn(dim)
    # return torch.zeros(dim)

def collect_state_data(encoded_trajectory=None, decoded_trajectory=None, labels=None, repetitions=None, output_folder="latest", image_reader=None, trajectory_dict=None, decoder_model=None):
    decoded_trajectory = torch.tensor(decoded_trajectory)
    trajectory_dict["joint_trajectory"] = decoded_trajectory.view(100, -1).tolist()
    safety_res = safety_check_module.check(decoded_trajectory.tolist(), args.execution_time)
    if safety_res.is_safe:
    	state_data = {}
        output_folder = package_path + "/sensing_data/slide_sensing/" + output_folder
        # os.makedirs(output_folder, exist_ok=True)
        if not os.path.exists(output_folder):
    		os.makedirs(output_folder)
        for label in labels:
            print("Collecting state data for stone labeled: {}".format(label))
            state_data[label] = {
                "x": [],
                "y": []
            }
            for repetition in range(repetitions):
                print("Repetition {}/{}".format(repetition+1, repetitions))
                command = raw_input("Press enter to execute the action: ")
                if "skip" != command:
                    execute_action(input_folder=False, tot_time_nsecs=args.execution_time, is_simulation=False, is_learning=True, t=trajectory_dict)
                command = raw_input("Press enter to evaluate the board\n")
                reward, distance, angle, stone_x, stone_y = evaluate_board(image_reader=image_reader)
                state_data[label]["x"].append(stone_x)
                state_data[label]["y"].append(stone_y)
                if repetition % 2 == 0:
					with open(output_folder+"/state_data_odd.txt", "w") as f:
						json.dump(state_data, f)
                else:
					with open(output_folder+"/state_data_even.txt", "w") as f:
						json.dump(state_data, f)

            # with open(output_folder+"/state_data.txt", "w") as f:
            #             json.dump(state_data, f)

def measure_performance(image_reader=None, trajectory_dict=None, algorithm=None, decoder_model=None, safety_check_module=None):
	state, label= get_state(algorithm.policy.in_dim, image_reader=image_reader, trajectory_dict=trajectory_dict, decoder_model=decoder_model)
	mean = algorithm.get_policy_mean(state)
	print ("mean: {}".format(mean))
	trajectory = decoder_model.decode(mean)
	smooth_trajectory = []
	for i in range(joints_number):
		smooth_trajectory.append(trajectory[i])
	for i, point in enumerate(trajectory[joints_number:], joints_number):
		smooth_trajectory.append(0.6*smooth_trajectory[i-joints_number]+0.4*point)
	smooth_trajectory = torch.tensor(smooth_trajectory)
	trajectory_dict["joint_trajectory"] = smooth_trajectory.view(100, -1).tolist()
	safety_res = safety_check_module.check(trajectory.tolist(), args.execution_time)
	if safety_res.is_safe:
		performance = {
			"tot": 0,
			"50": 0,
			"115": 0
		}
		for n in range(args.performance_repetition):
			command = raw_input("Press enter to measure performance")
			if "" != command:
				while True:
					if "print_means_history" == command:
						print("means_history:")
						print(algorithm.policy.means_history)
					if "q" == command:
						break
					command = raw_input("Insert command:\n")
			execute_action(input_folder=False, tot_time_nsecs=args.execution_time, is_simulation=False, is_learning=True, t=trajectory_dict)
			raw_input("Press enter to evaluate the board")
			reward, distance, angle, stone_x, stone_y = evaluate_board(image_reader=image_reader)
			try:
				if 0 <= int(distance) <= 50:
					performance["50"] += 1
					performance["115"] += 1
				elif 50 < int(distance) <= 115:
					performance["115"] += 1
				performance["tot"] += 1
			except ValueError:
				pass
		print("Red circle hit: {}\nBlue circle hit: {}".format(performance["50"], performance["115"]))
	else:
		print("Unsafe trajectory")

def test_policy(image_reader=None, algorithm=None, decoder_model=None, state=None, trajectory_dict=None):
	test_reward = 0
	mean = algorithm.get_policy_mean(state)
	trajectory = decoder_model.decode(mean)
	smooth_trajectory = []
	for i in range(joints_number):
		smooth_trajectory.append(trajectory[i])
	for i, point in enumerate(trajectory[joints_number:], joints_number):
		smooth_trajectory.append(0.6*smooth_trajectory[i-joints_number]+0.4*point)
	smooth_trajectory = torch.tensor(smooth_trajectory)
	trajectory_dict["joint_trajectory"] = smooth_trajectory.view(100, -1).tolist()
	safety_res = safety_check_module.check(trajectory.tolist(), args.execution_time)
	performance = {
		"tot": 0,
		"50": 0,
		"115": 0
	}
	if safety_res.is_safe:
		for n in range(max(args.performance_repetition, args.test_repetition)):
			raw_input("Press enter to execute a trajectory from the policy mean")
			execute_action(input_folder=False, tot_time_nsecs=args.execution_time, is_simulation=False, is_learning=True, t=trajectory_dict)
			raw_input("Press enter to evaluate the board")
			reward, distance, angle, stone_x, stone_y = evaluate_board(image_reader=image_reader)
			try:
				if 0 <= int(distance) <= 50:
					performance["50"] += 1
					performance["115"] += 1
				elif 50 < int(distance) <= 115:
					performance["115"] += 1
				performance["tot"] += 1
			except ValueError:
				pass
			test_reward += reward
		test_reward /= max(args.performance_repetition, args.test_repetition)
	else:
		test_reward = -1
	print("Red circle hit: {}\nBlue circle hit: {}".format(performance["50"], performance["115"]))	
	print ("Average reward of deterministic policy = {}".format(test_reward))
	return test_reward, mean, performance

def main(args):
    try:
        trajectory_dict = {
            "joint_trajectory": [],
            "joint_names": joint_names,
            "realease_frame": args.release_frame
        }
        plot_joints = False
        image_reader = image_reader_module.image_converter()
        items.append(image_reader)
        image_reader.initialize_board()
        algorithm = algorithm_module.ALGORITHM(args.state_dim, args.action_dim, args.learning_rate, plot=True, batch_size=args.batch_size)
        items.append(algorithm)
        if args.collect_state_data != False:
			collect_state_data(encoded_trajectory=None, decoded_trajectory=state_trajectory, labels=args.collect_state_data, repetitions=args.state_repetitions, output_folder=args.state_folder, image_reader=image_reader, trajectory_dict=trajectory_dict, decoder_model=decoder_model)
        if args.load_file != False:
            algorithm.load_model_state_dict(args.load_dir+args.load_file)
        elif args.load_checkpoint != False:
            algorithm.load_checkpoint(args.load_dir+args.load_checkpoint)
        else:
            algorithm.plot = False
            algorithm.pre_train(args.pre_train_epochs, args.pre_train_batch_size, args.pre_train_log_interval, target=torch.tensor(initial_means))
            print ("Pre train over")
            algorithm.plot = True
        ret = [0, 0]
        reward = None

        if args.measure_performance != False:
            measure_performance(image_reader=image_reader, trajectory_dict=trajectory_dict, algorithm=algorithm, decoder_model=decoder_model, safety_check_module=safety_check_module)
    
        safe_throws = 0
        epoch = 0
        while safe_throws < args.safe_throws:
        # for epoch in range(args.epochs):
            # t = 0
            # while t < args.batch_size:
            episode_reward = 0
            for t in range(args.batch_size):
                print ("t = {}".format(t))
                state, label = get_state(algorithm.policy.in_dim, image_reader=image_reader, trajectory_dict=trajectory_dict, decoder_model=decoder_model)
                command = True
                while "" != command:
                    command = raw_input("Enter command (leave blank to execute action): ")
                    if "set_action" == command:
                        while True:
                            try:
                                a = raw_input("Input the action in the form of a list ('q' to quit): ")
                                if "q" == a:
                                    break
                                action = torch.tensor(ast.literal_eval(a))
                                mean = torch.tensor(ast.literal_eval(a))
                                break
                            except:
                                print ("The action must be a python list\nEg: [1, 2, 3, 4, 5]")
                        if "q" != a:
                            break
                    if "test_policy" == command:
                        test_policy(image_reader, algorithm, decoder_model, state, trajectory_dict)
                    if "print_latent_space" == command:
                        try:
                            print(latent_space_data)
                        except:
                            print("Cannot print variable 'latent_space_data'.")

                if "set_action" != command:
                    cov_mat = torch.diag((torch.tensor(initial_stds))*math.pow(0.5, epoch))
                    print("cov_mat: ")
                    print(cov_mat)
                    if epoch == 0:
                        action, mean = algorithm.select_action(state, cov_mat=cov_mat, target_action=torch.tensor(initial_actions[t]))
                    else:
                        action, mean = algorithm.select_action(state, cov_mat=cov_mat)
                # action, mean = algorithm.select_action(state, cov_mat=cov_mat)
                if epoch % args.log_interval == 0 and t == 0 and algorithm.plot:
                    algorithm.update_graphs()
                # action = get_dummy_action(algorithm.policy.out_dim)
                trajectory = decoder_model.decode(action)

                # trajectory = decoder_model.decode(torch.tensor(mc_13_means))

                smooth_trajectory = []
                for i in range(joints_number):
                    smooth_trajectory.append(trajectory[i])
                for i, point in enumerate(trajectory[joints_number:], joints_number):
                    if i % joints_number == 0:
                        alpha = 0.9 - min((((0.9-0.6) / (50.0*joints_number)) * (i - joints_number)), 0.3)
                    smooth_trajectory.append(alpha*smooth_trajectory[i-joints_number]+(1-alpha)*point)
                    # smooth_trajectory.append(0.6*smooth_trajectory[i-joints_number]+0.4*point)
                smooth_trajectory = torch.tensor(smooth_trajectory)

                smooth_safety_res = safety_check_module.check(smooth_trajectory.tolist(), args.execution_time)
                safety_res = safety_check_module.check(trajectory.tolist(), args.execution_time)
                
                if safety_res.is_safe:
                    print("Distribution mean:")
                    print(mean)
                    print("Action to execute:")
                    print(action)
                    ret[0] += 1
                    trajectory_dict["joint_trajectory"] = smooth_trajectory.view(100, -1).tolist()
                    if plot_joints:
                        plotter_module.plot_joints(trajectory_dict["joint_trajectory"])
                    
                    cumulative_reward = 0
                    for n in range(args.action_repetition):
                        command = raw_input("Press enter to execute the action: ")
                        safe_throws += 1
                        print("\nn = {}".format(n+1))
                        if "skip" != command:
                            # execute_action(input_folder=False, tot_time_nsecs=args.safe_execution_time, is_simulation=False, is_learning=True, t=trajectory_dict)
                            execute_action(input_folder=False, tot_time_nsecs=args.execution_time, is_simulation=False, is_learning=True, t=trajectory_dict)
                        command = raw_input("Press enter to evaluate the board\n")
                        if "print rewards_history" == command:
                            print ("rewards_history:")
                            print (algorithm.policy.rewards_history)
                        reward, distance, angle, stone_x, stone_y = evaluate_board(image_reader=image_reader, epoch=epoch, batch_index=t, repetition=n, label=label)
						# while True:
                        #     distance, stone_x, stone_y = image_reader.evaluate_board()
                        #     if distance != -1:
                        #         if args.reward_type.upper() in ["D", "DISCRETE"]:
                        #             reward = max(0, 4 - distance//100)
                        #         elif args.reward_type.upper() in ["C", "CONTINUOUS"]:
                        #             reward = max(0, 4 - float(distance)/100)

                        #         angle = get_angle(stone_x, stone_y)
                        #         # if distance > 350:
                        #         #     reward = 0
                        #         # else:
                        #         #     reward = (1-(distance/350.0))**2
                        #         break
                        #     else:
                        #         command = raw_input("'c'=continue\n's'=set reward\n't'=try again\n'o'=out of bounds\n\nInput command: ")
                        #         if "c" == command:
                        #             break
                        #         elif "s" == command:
                        #             while True:
                        #                 try:
                        #                     r = raw_input("Set the reward: ")
                        #                     if "q" != r:
                        #                         reward = float(r)
                        #                         distance = "set"
                        #                         angle = "set"
                        #                     break
                        #                 except:
                        #                     print("INFO: Input 't' to try again evaluating the board")
                        #                     print("ERROR: The reward must be a float")
                        #             break
                        #         elif "o" == command:
                        #             reward = 0
                        #             distance = "out"
                        #             angle = "out"
                        #             break
                        #         elif "t" == command:
                        #             pass
                        cumulative_reward += reward
                        algorithm.set_stone_position(distance, angle)
                        print ("distance = {}".format(distance))
                        print ("reward = {}".format(reward))
                        print ("cumulative_reward = {}".format(cumulative_reward))
                    reward = float(cumulative_reward)/args.action_repetition
                else:
                    ret[1] += 1
                    reward = -safety_res.unsafe_pts
                    algorithm.set_stone_position("unsafe", "unsafe")
                print (ret)
                print ("unsafe_pts = " + str(safety_res.unsafe_pts))

                print ("reward = {}".format(reward))      
                algorithm.set_reward(reward)
                episode_reward += reward
			
            episode_reward /= int(args.batch_size)
            algorithm.set_episode_reward(episode_reward)
            loss = algorithm.finish_episode()

            raw_input("Press enter to test the policy")
            latest_det_reward, latest_det_mean, performance = test_policy(image_reader, algorithm, decoder_model, state, trajectory_dict)
            algorithm.set_deterministic_policy_performance(performance)
            algorithm.set_deterministic_policy_reward(latest_det_reward)
            algorithm.set_deterministic_policy_mean(latest_det_mean)

            print("Saving policy model...")
            algorithm.save_model_state_dict(save_path)
            checkpoint_save_path = args.save_dir+"checkpoint/"+datetime.now().strftime("%Y-%m-%d_%H:%M:%S")+"_r"+str(round(latest_det_reward, 3))+".tar"
            algorithm.save_checkpoint(checkpoint_save_path)
            print("Policy model saved...")

            if epoch % args.log_interval == 0:
                print('Episode {}\tEpisode avg reward: {:.2f}'.format(
                    epoch, episode_reward))
            epoch += 1

        algorithm.update_graphs()
        raw_input("Execution finished, press enter to close the program.")
        raw_input("Execution finished, press enter to close the program.")
        raw_input("Execution finished, press enter to close the program.")
        raw_input("Execution finished, press enter to close the program.")
        close_all(items)

    except KeyboardInterrupt:
        print("Shutting down")
        close_all(items)


if __name__ == '__main__':
    main(args)